{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dbff38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\G'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\G'\n",
      "C:\\Users\\bekab\\AppData\\Local\\Temp\\ipykernel_30940\\434662613.py:13: SyntaxWarning: invalid escape sequence '\\G'\n",
      "  df = pd.read_csv(\"G:\\ОАД\\НИРС\\Greenhouse Plant Growth Metrics.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Базовые метрики:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1500\n",
      "           1       1.00      1.00      1.00      1500\n",
      "           2       1.00      1.00      1.00      1500\n",
      "           3       1.00      1.00      1.00      1500\n",
      "           4       1.00      1.00      1.00      1500\n",
      "           5       1.00      1.00      1.00      1500\n",
      "\n",
      "    accuracy                           1.00      9000\n",
      "   macro avg       1.00      1.00      1.00      9000\n",
      "weighted avg       1.00      1.00      1.00      9000\n",
      "\n",
      "Матрица ошибок:\n",
      " [[1500    0    0    0    0    0]\n",
      " [   0 1500    0    0    0    0]\n",
      " [   0    0 1500    0    0    0]\n",
      " [   0    0    0 1500    0    0]\n",
      " [   0    0    0    0 1500    0]\n",
      " [   0    0    0    0    0 1500]]\n",
      "\n",
      "Метрики для GridSearch:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1500\n",
      "           1       1.00      1.00      1.00      1500\n",
      "           2       1.00      1.00      1.00      1500\n",
      "           3       1.00      1.00      1.00      1500\n",
      "           4       1.00      1.00      1.00      1500\n",
      "           5       1.00      1.00      1.00      1500\n",
      "\n",
      "    accuracy                           1.00      9000\n",
      "   macro avg       1.00      1.00      1.00      9000\n",
      "weighted avg       1.00      1.00      1.00      9000\n",
      "\n",
      "Лучшие параметры: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'euclidean', 'metric_params': None, 'n_jobs': None, 'n_neighbors': np.int64(1), 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "\n",
      "Метрики для RandomizedSearch:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1500\n",
      "           1       1.00      1.00      1.00      1500\n",
      "           2       1.00      1.00      1.00      1500\n",
      "           3       1.00      1.00      1.00      1500\n",
      "           4       1.00      1.00      1.00      1500\n",
      "           5       1.00      1.00      1.00      1500\n",
      "\n",
      "    accuracy                           1.00      9000\n",
      "   macro avg       1.00      1.00      1.00      9000\n",
      "weighted avg       1.00      1.00      1.00      9000\n",
      "\n",
      "Лучшие параметры: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'euclidean', 'metric_params': None, 'n_jobs': None, 'n_neighbors': np.int64(23), 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "Base KNN (k=5) Accuracy: 1.0000\n",
      "Base KNN (k=5) F1-score: 1.0000\n",
      "\n",
      "GridSearchCV Accuracy: 1.0000\n",
      "GridSearchCV F1-score: 1.0000\n",
      "\n",
      "RandomizedSearchCV Accuracy: 1.0000\n",
      "RandomizedSearchCV F1-score: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Загрузка данных из CSV-файла\n",
    "df = pd.read_csv(\"G:\\ОАД\\НИРС\\Greenhouse Plant Growth Metrics.csv\")\n",
    "\n",
    "# Удаляем ненужный столбец-идентификатор (не несет полезной информации для обучения)\n",
    "df.drop('Random', axis=1, inplace=True)\n",
    "\n",
    "# Разделяем признаки на числовые и категориальные\n",
    "numerical_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "# Создаем предобработчик для числовых и категориальных признаков\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Для числовых — замена пропусков на медиану\n",
    "        ('num', SimpleImputer(strategy='median'), numerical_cols),\n",
    "        # Для категориальных — замена пропусков на наиболее частое значение\n",
    "        ('cat', SimpleImputer(strategy='most_frequent'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Применяем предобработку и собираем DataFrame обратно\n",
    "df_processed = pd.DataFrame(preprocessor.fit_transform(df), \n",
    "                           columns=numerical_cols + categorical_cols)\n",
    "\n",
    "# Кодируем категориальную целевую переменную 'Class' в числовой формат\n",
    "le = LabelEncoder()\n",
    "df_processed['Class'] = le.fit_transform(df_processed['Class'])\n",
    "\n",
    "# Разделяем данные на признаки (X) и целевую переменную (y)\n",
    "X = df_processed.drop('Class', axis=1)\n",
    "y = df_processed['Class']\n",
    "\n",
    "# Масштабируем признаки с помощью StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Разделяем данные на обучающую и тестовую выборки (30% — тест)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, \n",
    "    test_size=0.3, \n",
    "    stratify=y,   # сохраняем пропорции классов\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Обучаем базовую модель KNN с k=5\n",
    "knn_base = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_base.fit(X_train, y_train)\n",
    "y_pred_base = knn_base.predict(X_test)\n",
    "\n",
    "# Выводим базовые метрики\n",
    "print(\"Базовые метрики:\")\n",
    "print(classification_report(y_test, y_pred_base))\n",
    "print(\"Матрица ошибок:\\n\", confusion_matrix(y_test, y_pred_base))\n",
    "\n",
    "# Задаем сетку гиперпараметров для подбора\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(1, 31),  # k от 1 до 30\n",
    "    'weights': ['uniform', 'distance'],  # веса: равные или по расстоянию\n",
    "    'metric': ['euclidean', 'manhattan']  # метрики расстояния\n",
    "}\n",
    "\n",
    "# Определяем стратегии кросс-валидации\n",
    "strategies = {\n",
    "    'StratifiedKFold': StratifiedKFold(n_splits=5),  # учитывает распределение классов\n",
    "    'KFold': KFold(n_splits=5, shuffle=True)  # случайное перемешивание без учета классов\n",
    "}\n",
    "000000000\n",
    "# Подбор гиперпараметров через GridSearchCV с кросс-валидацией StratifiedKFold\n",
    "grid_search = GridSearchCV(\n",
    "    KNeighborsClassifier(), \n",
    "    param_grid, \n",
    "    cv=strategies['StratifiedKFold'],\n",
    "    scoring='f1_weighted',  # метрика качества: взвешенное F1\n",
    "    n_jobs=-1  # использование всех доступных ядер\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Подбор гиперпараметров через RandomizedSearchCV с кросс-валидацией KFold\n",
    "random_search = RandomizedSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid,\n",
    "    n_iter=20,  # количество случайных комбинаций\n",
    "    cv=strategies['KFold'],\n",
    "    scoring='f1_weighted',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Извлекаем лучшие модели по результатам поиска\n",
    "best_knn_grid = grid_search.best_estimator_\n",
    "best_knn_random = random_search.best_estimator_\n",
    "\n",
    "# Оцениваем каждую из лучших моделей\n",
    "for name, model in [('GridSearch', best_knn_grid), \n",
    "                   ('RandomizedSearch', best_knn_random)]:\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nМетрики для {name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Лучшие параметры: {model.get_params()}\\n\")\n",
    "\n",
    "# Сравниваем все три модели по точности и F1-метрике\n",
    "models = {\n",
    "    'Base KNN (k=5)': knn_base,\n",
    "    'GridSearchCV': best_knn_grid,\n",
    "    'RandomizedSearchCV': best_knn_random\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"{name} Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"{name} F1-score: {classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score']:.4f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
