{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Лабораторная работа\n",
        "## Ансамбли моделей машинного обучения. Часть 2.\n",
        "\n",
        "#Цель работы**: изучение ансамблей моделей машинного обучения.\n",
        "\n",
        "#Используемый датасет**: Processed_Plant_Growth_Metrics.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Установка необходимых библиотек\n",
        "#pip install scikit-learn pandas numpy matplotlib seaborn gmdh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'GMDH_COMBI' from 'gmdh.gmdh' (c:\\Users\\bekab\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gmdh\\gmdh.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score, mean_absolute_error\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgmdh\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgmdh\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgmdh\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GMDH_COMBI \u001b[38;5;28;01mas\u001b[39;00m COMBI, GMDH_MULTI \u001b[38;5;28;01mas\u001b[39;00m MULTI  \u001b[38;5;66;03m# возможные альтернативные имена\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Настройка отображения графиков\u001b[39;00m\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mggplot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'GMDH_COMBI' from 'gmdh.gmdh' (c:\\Users\\bekab\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gmdh\\gmdh.py)"
          ]
        }
      ],
      "source": [
        "# Импорт необходимых библиотек\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import gmdh\n",
        "from gmdh.gmdh import GMDH_COMBI as COMBI, GMDH_MULTI as MULTI  # возможные альтернативные имена\n",
        "\n",
        "# Настройка отображения графиков\n",
        "plt.style.use('ggplot')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "sns.set(font_scale=1.2)\n",
        "\n",
        "# Для воспроизводимости результатов\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загрузка данных\n",
        "df = pd.read_csv('Processed_Plant_Growth_Metrics.csv')\n",
        "\n",
        "# Вывод первых 5 строк данных\n",
        "print(\"Первые 5 строк набора данных:\")\n",
        "display(df.head())\n",
        "\n",
        "# Информация о наборе данных\n",
        "print(\"\\nИнформация о наборе данных:\")\n",
        "display(df.info())\n",
        "\n",
        "# Статистическое описание\n",
        "print(\"\\nСтатистическое описание набора данных:\")\n",
        "display(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Проверка на пропущенные значения\n",
        "print(\"Количество пропущенных значений в каждом столбце:\")\n",
        "display(df.isnull().sum())\n",
        "\n",
        "# Проверка наличия дубликатов\n",
        "print(f\"\\nКоличество дубликатов: {df.duplicated().sum()}\")\n",
        "\n",
        "# Анализ целевой переменной\n",
        "print(\"\\nАнализ целевой переменной (Growth_Rate):\")\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df['Growth_Rate'], kde=True)\n",
        "plt.title('Распределение Growth_Rate')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(y=df['Growth_Rate'])\n",
        "plt.title('Boxplot для Growth_Rate')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Корреляционная матрица\n",
        "plt.figure(figsize=(14, 10))\n",
        "corr = df.select_dtypes(include=[np.number]).corr()\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "sns.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", cmap='coolwarm', center=0)\n",
        "plt.title('Корреляционная матрица числовых признаков')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Подготовка данных для моделирования\n",
        "\n",
        "# Определение числовых и категориальных признаков\n",
        "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Удаляем целевую переменную из списка числовых признаков\n",
        "if 'Growth_Rate' in numeric_features:\n",
        "    numeric_features.remove('Growth_Rate')\n",
        "\n",
        "print(\"Числовые признаки:\", numeric_features)\n",
        "print(\"Категориальные признаки:\", categorical_features)\n",
        "\n",
        "# Разделение на признаки и целевую переменную\n",
        "X = df.drop('Growth_Rate', axis=1)\n",
        "y = df['Growth_Rate']\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
        "print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
        "\n",
        "# Создание препроцессора для числовых и категориальных признаков\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Объединение преобразователей\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Применение препроцессора к данным\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "print(f\"Размер обучающей выборки после препроцессинга: {X_train_preprocessed.shape}\")\n",
        "print(f\"Размер тестовой выборки после препроцессинга: {X_test_preprocessed.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Модель 1: Стекинг (Stacking)\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "\n",
        "# Определение базовых моделей для стекинга\n",
        "base_models = [\n",
        "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42)),\n",
        "    ('gbr', GradientBoostingRegressor(random_state=42)),\n",
        "    ('ridge', Ridge(random_state=42))\n",
        "]\n",
        "\n",
        "# Создание модели стекинга с линейной регрессией в качестве мета-модели\n",
        "stacking_model = StackingRegressor(\n",
        "    estimators=base_models,\n",
        "    final_estimator=LinearRegression(),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Обучение стекинг-модели\n",
        "print(\"Обучение стекинг-модели...\")\n",
        "stacking_model.fit(X_train_preprocessed, y_train)\n",
        "\n",
        "# Предсказание значений\n",
        "y_pred_stacking = stacking_model.predict(X_test_preprocessed)\n",
        "\n",
        "# Оценка качества модели\n",
        "mse_stacking = mean_squared_error(y_test, y_pred_stacking)\n",
        "rmse_stacking = np.sqrt(mse_stacking)\n",
        "mae_stacking = mean_absolute_error(y_test, y_pred_stacking)\n",
        "r2_stacking = r2_score(y_test, y_pred_stacking)\n",
        "\n",
        "print(\"Метрики качества для стекинг-модели:\")\n",
        "print(f\"MSE: {mse_stacking:.4f}\")\n",
        "print(f\"RMSE: {rmse_stacking:.4f}\")\n",
        "print(f\"MAE: {mae_stacking:.4f}\")\n",
        "print(f\"R²: {r2_stacking:.4f}\")\n",
        "\n",
        "# Визуализация результатов\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_stacking, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Фактические значения')\n",
        "plt.ylabel('Предсказанные значения')\n",
        "plt.title('Стекинг-модель: предсказанные vs фактические значения')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Модель 2: Многослойный персептрон (МLP)\n",
        "# Создание и обучение MLP модели\n",
        "mlp_model = MLPRegressor(\n",
        "    hidden_layer_sizes=(100, 50, 25), \n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    alpha=0.0001,\n",
        "    batch_size='auto',\n",
        "    learning_rate='adaptive',\n",
        "    max_iter=1000,\n",
        "    random_state=42,\n",
        "    early_stopping=True,\n",
        "    validation_fraction=0.1,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Обучение модели многослойного персептрона...\")\n",
        "mlp_model.fit(X_train_preprocessed, y_train)\n",
        "\n",
        "# Предсказание значений\n",
        "y_pred_mlp = mlp_model.predict(X_test_preprocessed)\n",
        "\n",
        "# Оценка качества модели\n",
        "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
        "rmse_mlp = np.sqrt(mse_mlp)\n",
        "mae_mlp = mean_absolute_error(y_test, y_pred_mlp)\n",
        "r2_mlp = r2_score(y_test, y_pred_mlp)\n",
        "\n",
        "print(\"Метрики качества для модели многослойного персептрона:\")\n",
        "print(f\"MSE: {mse_mlp:.4f}\")\n",
        "print(f\"RMSE: {rmse_mlp:.4f}\")\n",
        "print(f\"MAE: {mae_mlp:.4f}\")\n",
        "print(f\"R²: {r2_mlp:.4f}\")\n",
        "\n",
        "# Визуализация результатов\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_mlp, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Фактические значения')\n",
        "plt.ylabel('Предсказанные значения')\n",
        "plt.title('Многослойный персептрон: предсказанные vs фактические значения')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Подготовка данных для моделей МГУА\n",
        "# Для моделей МГУА нам нужны numpy массивы\n",
        "X_train_np = X_train_preprocessed.copy()\n",
        "X_test_np = X_test_preprocessed.copy()\n",
        "\n",
        "# Проверка, является ли X_train_preprocessed разреженной матрицей\n",
        "from scipy.sparse import issparse\n",
        "\n",
        "if issparse(X_train_preprocessed):\n",
        "    X_train_np = X_train_preprocessed.toarray()\n",
        "    X_test_np = X_test_preprocessed.toarray()\n",
        "\n",
        "print(f\"Форма данных для МГУА моделей - X_train: {X_train_np.shape}, X_test: {X_test_np.shape}\")\n",
        "\n",
        "# Модель 3: COMBI (линейный метод МГУА)\n",
        "print(\"Обучение модели COMBI...\")\n",
        "combi_model = COMBI(\n",
        "    ref_functions=('const', 'linear'),  # Используем константу и линейную функцию в качестве опорных\n",
        "    criterion_type='test_mse',          # Критерий качества - MSE на тестовой выборке\n",
        "    criterion_minimize=True,             # Минимизировать критерий\n",
        "    p_max=3,                             # Максимальное число переменных в модели\n",
        "    verbose=True                         # Вывод информации о ходе обучения\n",
        ")\n",
        "\n",
        "# Разделение данных на обучающую и валидационную выборки для МГУА\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_gmdh, X_val_gmdh, y_train_gmdh, y_val_gmdh = train_test_split(\n",
        "    X_train_np, y_train, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "# Обучение модели COMBI\n",
        "combi_model.fit(X_train_gmdh, y_train_gmdh, X_val_gmdh, y_val_gmdh)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred_combi = combi_model.predict(X_test_np)\n",
        "\n",
        "# Оценка качества модели\n",
        "mse_combi = mean_squared_error(y_test, y_pred_combi)\n",
        "rmse_combi = np.sqrt(mse_combi)\n",
        "mae_combi = mean_absolute_error(y_test, y_pred_combi)\n",
        "r2_combi = r2_score(y_test, y_pred_combi)\n",
        "\n",
        "print(\"Метрики качества для модели COMBI:\")\n",
        "print(f\"MSE: {mse_combi:.4f}\")\n",
        "print(f\"RMSE: {rmse_combi:.4f}\")\n",
        "print(f\"MAE: {mae_combi:.4f}\")\n",
        "print(f\"R²: {r2_combi:.4f}\")\n",
        "\n",
        "# Визуализация результатов\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_combi, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Фактические значения')\n",
        "plt.ylabel('Предсказанные значения')\n",
        "plt.title('Модель COMBI: предсказанные vs фактические значения')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Модель 4: MIA (нелинейный метод МГУА)\n",
        "print(\"Обучение модели MIA...\")\n",
        "mia_model = MIA(\n",
        "    ref_functions=('const', 'linear', 'quad'),  # Используем константу, линейную и квадратичную функции\n",
        "    max_layer_count=5,              # Максимальное число слоев\n",
        "    criterion_type='test_mse',      # Критерий качества - MSE на тестовой выборке\n",
        "    criterion_minimize=True,         # Минимизировать критерий\n",
        "    p_max=3,                         # Максимальное число переменных в модели\n",
        "    verbose=True                     # Вывод информации о ходе обучения\n",
        ")\n",
        "\n",
        "# Обучение модели MIA\n",
        "mia_model.fit(X_train_gmdh, y_train_gmdh, X_val_gmdh, y_val_gmdh)\n",
        "\n",
        "# Предсказание на тестовой выборке\n",
        "y_pred_mia = mia_model.predict(X_test_np)\n",
        "\n",
        "# Оценка качества модели\n",
        "mse_mia = mean_squared_error(y_test, y_pred_mia)\n",
        "rmse_mia = np.sqrt(mse_mia)\n",
        "mae_mia = mean_absolute_error(y_test, y_pred_mia)\n",
        "r2_mia = r2_score(y_test, y_pred_mia)\n",
        "\n",
        "print(\"Метрики качества для модели MIA:\")\n",
        "print(f\"MSE: {mse_mia:.4f}\")\n",
        "print(f\"RMSE: {rmse_mia:.4f}\")\n",
        "print(f\"MAE: {mae_mia:.4f}\")\n",
        "print(f\"R²: {r2_mia:.4f}\")\n",
        "\n",
        "# Визуализация результатов\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_mia, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Фактические значения')\n",
        "plt.ylabel('Предсказанные значения')\n",
        "plt.title('Модель MIA: предсказанные vs фактические значения')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сравнение всех моделей\n",
        "models = {\n",
        "    'Stacking': [mse_stacking, rmse_stacking, mae_stacking, r2_stacking],\n",
        "    'MLP': [mse_mlp, rmse_mlp, mae_mlp, r2_mlp],\n",
        "    'COMBI (МГУА)': [mse_combi, rmse_combi, mae_combi, r2_combi],\n",
        "    'MIA (МГУА)': [mse_mia, rmse_mia, mae_mia, r2_mia]\n",
        "}\n",
        "\n",
        "# Создание таблицы сравнения\n",
        "comparison_df = pd.DataFrame.from_dict(models, \n",
        "                                       orient='index',\n",
        "                                       columns=['MSE', 'RMSE', 'MAE', 'R²'])\n",
        "display(comparison_df)\n",
        "\n",
        "# Визуализация сравнения по метрикам\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# RMSE\n",
        "plt.subplot(1, 3, 1)\n",
        "comparison_df['RMSE'].plot(kind='bar', color='skyblue')\n",
        "plt.title('RMSE для всех моделей')\n",
        "plt.ylabel('RMSE')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y')\n",
        "\n",
        "# MAE\n",
        "plt.subplot(1, 3, 2)\n",
        "comparison_df['MAE'].plot(kind='bar', color='lightgreen')\n",
        "plt.title('MAE для всех моделей')\n",
        "plt.ylabel('MAE')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y')\n",
        "\n",
        "# R²\n",
        "plt.subplot(1, 3, 3)\n",
        "comparison_df['R²'].plot(kind='bar', color='salmon')\n",
        "plt.title('R² для всех моделей')\n",
        "plt.ylabel('R²')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Визуализация предсказаний лучшей модели (определяем по наилучшему R²)\n",
        "best_model = comparison_df['R²'].idxmax()\n",
        "print(f\"Лучшая модель по метрике R²: {best_model}\")\n",
        "\n",
        "# Получаем предсказания лучшей модели\n",
        "if best_model == 'Stacking':\n",
        "    y_pred_best = y_pred_stacking\n",
        "elif best_model == 'MLP':\n",
        "    y_pred_best = y_pred_mlp\n",
        "elif best_model == 'COMBI (МГУА)':\n",
        "    y_pred_best = y_pred_combi\n",
        "elif best_model == 'MIA (МГУА)':\n",
        "    y_pred_best = y_pred_mia\n",
        "\n",
        "# Визуализация предсказаний лучшей модели\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_best, alpha=0.5, color='blue')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Фактические значения')\n",
        "plt.ylabel('Предсказанные значения')\n",
        "plt.title(f'Лучшая модель ({best_model}): предсказанные vs фактические значения')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Оценка важности признаков для лучшей модели\n",
        "# Для стекинга можно оценить важность признаков по базовым моделям\n",
        "# Например, если RandomForestRegressor был лучшим из базовых моделей\n",
        "\n",
        "if best_model == 'Stacking':\n",
        "    # Берем базовую модель RandomForest из стекинга\n",
        "    for name, model in stacking_model.estimators_:\n",
        "        if name == 'rf':\n",
        "            rf_model = model\n",
        "            \n",
        "    # Если есть преобразователь признаков для стекинга\n",
        "    feature_names = []\n",
        "    if hasattr(preprocessor, 'get_feature_names_out'):\n",
        "        feature_names = preprocessor.get_feature_names_out()\n",
        "    else:\n",
        "        feature_names = [f'feature_{i}' for i in range(X_train_preprocessed.shape[1])]\n",
        "    \n",
        "    # Получаем важность признаков\n",
        "    importances = rf_model.feature_importances_\n",
        "    \n",
        "    # Создаем DataFrame для сортировки\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': importances\n",
        "    })\n",
        "    \n",
        "    # Сортировка по важности\n",
        "    feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
        "    \n",
        "    # Визуализация\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(20))\n",
        "    plt.title('Топ-20 важных признаков (RandomForest из стекинга)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Для MLP нет встроенного метода оценки важности признаков, но можно использовать \n",
        "# пермутационную важность\n",
        "elif best_model == 'MLP':\n",
        "    from sklearn.inspection import permutation_importance\n",
        "    \n",
        "    # Вычисление пермутационной важности\n",
        "    perm_importance = permutation_importance(mlp_model, X_test_preprocessed, y_test, n_repeats=10, random_state=42)\n",
        "    \n",
        "    # Получаем имена признаков\n",
        "    feature_names = []\n",
        "    if hasattr(preprocessor, 'get_feature_names_out'):\n",
        "        feature_names = preprocessor.get_feature_names_out()\n",
        "    else:\n",
        "        feature_names = [f'feature_{i}' for i in range(X_train_preprocessed.shape[1])]\n",
        "    \n",
        "    # Создаем DataFrame для сортировки\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': perm_importance.importances_mean\n",
        "    })\n",
        "    \n",
        "    # Сортировка по важности\n",
        "    feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
        "    \n",
        "    # Визуализация\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(20))\n",
        "    plt.title('Топ-20 важных признаков (MLP - пермутационная важность)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "# Для моделей МГУА можно вывести структуру модели и коэффициенты\n",
        "elif 'МГУА' in best_model:\n",
        "    if best_model == 'COMBI (МГУА)':\n",
        "        gmdh_model = combi_model\n",
        "    else:\n",
        "        gmdh_model = mia_model\n",
        "        \n",
        "    print(f\"Информация о модели {best_model}:\")\n",
        "    print(f\"Структура модели: {gmdh_model}\")\n",
        "    # Пытаемся вывести коэффициенты или другую информацию о модели\n",
        "    if hasattr(gmdh_model, 'coefs_'):\n",
        "        print(\"Коэффициенты модели:\")\n",
        "        for i, coef in enumerate(gmdh_model.coefs_):\n",
        "            print(f\"Коэффициент {i}: {coef}\")\n",
        "    \n",
        "    # Попытка оценить важность признаков с помощью пермутационной важности\n",
        "    from sklearn.inspection import permutation_importance\n",
        "    \n",
        "    # Получаем имена признаков\n",
        "    feature_names = []\n",
        "    if hasattr(preprocessor, 'get_feature_names_out'):\n",
        "        feature_names = preprocessor.get_feature_names_out()\n",
        "    else:\n",
        "        feature_names = [f'feature_{i}' for i in range(X_train_np.shape[1])]\n",
        "    \n",
        "    # Вычисление пермутационной важности\n",
        "    perm_importance = permutation_importance(gmdh_model, X_test_np, y_test, n_repeats=5, random_state=42)\n",
        "    \n",
        "    # Создаем DataFrame для сортировки\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': perm_importance.importances_mean\n",
        "    })\n",
        "    \n",
        "    # Сортировка по важности\n",
        "    feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
        "    \n",
        "    # Визуализация\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(20))\n",
        "    plt.title(f'Топ-20 важных признаков ({best_model} - пермутационная важность)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Выводы по результатам работы\n",
        "\n",
        "## Результаты и сравнение моделей:\n",
        "\n",
        "1. **Стекинг (Stacking)**: Ансамблевый метод, объединяющий предсказания нескольких моделей (Random Forest, Gradient Boosting, Ridge) с помощью метамодели (линейная регрессия).\n",
        "\n",
        "2. **Многослойный персептрон (MLP)**: Нейронная сеть с тремя скрытыми слоями (100, 50 и 25 нейронов).\n",
        "\n",
        "3. **COMBI (линейный метод МГУА)**: Метод группового учета аргументов, использующий линейные зависимости.\n",
        "\n",
        "4. **MIA (нелинейный метод МГУА)**: Метод группового учета аргументов с нелинейными опорными функциями.\n",
        "\n",
        "По результатам сравнения метрик качества моделей, лучшие результаты показала [здесь будет название лучшей модели по R²]. Это демонстрирует эффективность [соответствующего подхода] для решения задачи регрессии на данном наборе данных.\n",
        "\n",
        "## Особенности МГУА моделей:\n",
        "\n",
        "МГУА модели показали [здесь будет результат сравнения МГУА с другими моделями]. Библиотека GMDH позволяет строить интерпретируемые модели с автоматическим выбором структуры, что является их преимуществом по сравнению с \"черными ящиками\" вроде нейронных сетей.\n",
        "\n",
        "## Общий вывод:\n",
        "\n",
        "В данной работе мы применили различные ансамблевые методы машинного обучения для решения задачи регрессии. Сравнение моделей показало, что для данного набора данных о росте растений наиболее эффективным методом является [здесь будет название лучшей модели].\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
