# fraud_detection_app.py
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import class_weight

# –£–ª—É—á—à–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
@st.cache_data
def load_data():
    try:
        df = pd.read_csv("upi_transactions_2024.csv")
        st.success("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        st.stop()

# –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
def preprocess_data(df):
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    required_columns = ['transaction id', 'timestamp', 'fraud_flag']
    for col in required_columns:
        if col not in df.columns:
            st.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞: {col}")
            st.stop()
    
    df = df.drop(['transaction id', 'timestamp'], axis=1, errors='ignore')
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    cat_cols = df.select_dtypes(include=['object', 'category']).columns
    for col in cat_cols:
        if col != 'fraud_flag':  # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –Ω–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞–µ—Ç—Å—è
            le = LabelEncoder()
            df[col] = le.fit_transform(df[col].astype(str))
    
    return df

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
def main():
    st.set_page_config(page_title="Fraud Detection System", layout="wide")
    st.title("üîç –°–∏—Å—Ç–µ–º–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π UPI")
    st.markdown("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ ML –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = load_data()
    
    # –ü–æ–∫–∞–∑–∞—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
    with st.expander("–ü—Ä–æ—Å–º–æ—Ç—Ä —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"):
        st.dataframe(df.head())
        st.write(f"–†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {df.shape[0]} —Å—Ç—Ä–æ–∫, {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
    
    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
    df_processed = preprocess_data(df)
    
    # –ü–æ–∫–∞–∑–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    with st.expander("–ü—Ä–æ—Å–º–æ—Ç—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"):
        st.dataframe(df_processed.head())
        st.write("–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        st.write(df_processed.dtypes)
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X = df_processed.drop('fraud_flag', axis=1)
    y = df_processed['fraud_flag']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    # –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
    st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_name = st.sidebar.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å",
        ["Logistic Regression", "Random Forest", "Gradient Boosting"]
    )
    
    # –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    params = {}
    if model_name == "Random Forest":
        params['n_estimators'] = st.sidebar.slider("–ß–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤", 10, 200, 100)
        params['max_depth'] = st.sidebar.slider("–ú–∞–∫—Å. –≥–ª—É–±–∏–Ω–∞", 2, 50, 10)
        params['class_weight'] = 'balanced' if st.sidebar.checkbox("–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤", True) else None
    elif model_name == "Gradient Boosting":
        params['n_estimators'] = st.sidebar.slider("–ß–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤", 10, 200, 100)
        params['learning_rate'] = st.sidebar.slider("Learning Rate", 0.01, 1.0, 0.1)
        params['subsample'] = st.sidebar.slider("Subsample", 0.1, 1.0, 0.8)
    elif model_name == "Logistic Regression":
        params['max_iter'] = st.sidebar.slider("–ú–∞–∫—Å. –∏—Ç–µ—Ä–∞—Ü–∏–π", 100, 2000, 1000)
        params['class_weight'] = 'balanced' if st.sidebar.checkbox("–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤", True) else None
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    if st.sidebar.button("üöÄ –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å", type="primary"):
        with st.spinner('–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...'):
            try:
                # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
                if model_name == "Logistic Regression":
                    model = LogisticRegression(**params)
                elif model_name == "Random Forest":
                    model = RandomForestClassifier(**params)
                elif model_name == "Gradient Boosting":
                    model = GradientBoostingClassifier(**params)
                
                # –û–±—É—á–µ–Ω–∏–µ
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                y_prob = model.predict_proba(X_test)[:, 1]
                
                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                st.success("–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞!")
                
                # –û—Ç—á–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                st.subheader(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏: {model_name}")
                st.code(classification_report(y_test, y_pred))
                
                # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
                st.subheader("üìâ –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")
                cm = confusion_matrix(y_test, y_pred)
                fig, ax = plt.subplots(figsize=(8, 6))
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, 
                            annot_kws={"size": 16}, 
                            xticklabels=['–ó–∞–∫–æ–Ω–Ω—ã–µ', '–ú–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ'],
                            yticklabels=['–ó–∞–∫–æ–Ω–Ω—ã–µ', '–ú–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ'])
                ax.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ')
                ax.set_ylabel('–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ')
                ax.set_title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫')
                st.pyplot(fig)
                plt.close(fig)
                
                # ROC-–∫—Ä–∏–≤–∞—è
                st.subheader("üìà ROC-–∫—Ä–∏–≤–∞—è")
                fpr, tpr, thresholds = roc_curve(y_test, y_prob)
                roc_auc = auc(fpr, tpr)
                
                fig, ax = plt.subplots(figsize=(8, 6))
                ax.plot(fpr, tpr, color='darkorange', lw=2, 
                         label=f'ROC –∫—Ä–∏–≤–∞—è (AUC = {roc_auc:.2f})')
                ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
                ax.set_xlim([0.0, 1.0])
                ax.set_ylim([0.0, 1.05])
                ax.set_xlabel('False Positive Rate')
                ax.set_ylabel('True Positive Rate')
                ax.set_title('ROC-–∫—Ä–∏–≤–∞—è')
                ax.legend(loc="lower right")
                st.pyplot(fig)
                plt.close(fig)
                
                # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                if hasattr(model, 'feature_importances_'):
                    st.subheader("üîç –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                    feature_importances = pd.Series(model.feature_importances_, index=X.columns)
                    top_features = feature_importances.sort_values(ascending=False).head(10)
                    
                    fig, ax = plt.subplots(figsize=(10, 6))
                    top_features.plot(kind='barh', ax=ax, color='skyblue')
                    ax.set_title('–¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤')
                    ax.set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')
                    st.pyplot(fig)
                    plt.close(fig)
                
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∫–ª–∞—Å—Å–æ–≤
    st.sidebar.header("‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö")
    fraud_percentage = (y.sum() / len(y)) * 100
    st.sidebar.metric("–ú–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π", 
                      f"{y.sum():,} ({fraud_percentage:.2f}%)")
    st.sidebar.metric("–ó–∞–∫–æ–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π", 
                      f"{(len(y) - y.sum()):,} ({(100 - fraud_percentage):.2f}%)")
    
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if fraud_percentage < 5:
        st.sidebar.warning("–í–Ω–∏–º–∞–Ω–∏–µ: –¥–∞–Ω–Ω—ã–µ —Å–∏–ª—å–Ω–æ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫—É –∫–ª–∞—Å—Å–æ–≤.")

if __name__ == "__main__":
    main()